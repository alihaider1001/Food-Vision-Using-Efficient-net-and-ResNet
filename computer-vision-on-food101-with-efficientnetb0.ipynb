{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30213,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Food Vision Project : A story of classifying food images","metadata":{}},{"cell_type":"markdown","source":"<p style=\"text-align:center;\"><img src=\"https://i.pinimg.com/564x/70/b1/55/70b155d20647d2863805da7559cf169d.jpg\" alt=\"Girl in a jacket\" width=\"500\" height=\"500\" class=\"center\"></p>","metadata":{}},{"cell_type":"markdown","source":"> <div class=\"alert alert-block alert-danger\">\n<b>Danger:</b> This notebook can make you hungry, since it includes very delicious foods!\n</div>","metadata":{}},{"cell_type":"markdown","source":"Let's create some helper functions that will help us in many points during the project.\nHere is the functions that we will build now :\n* **load_and_prep_image** : A function to import an image and resize it to be able to be used with our model\n\n* **make_confusion_matrix** : A function to create confusion matrix that is different than the Scikit Learn's function\n\n* **pred_and_plot** :a function to predict on images and plot them (works with multi-class)\n\n* **create_tensorboard_callback** : Creates a TensorBoard callback instand to store log files.\n\n* **plot_loss_curves** : Returns separate loss curves for training and validation metrics.\n\n* **compare_historys** : Compares two TensorFlow model History objects.\n\n* **unzip_data** : Unzips filename into the current working directory.\n\n* **walk_through_dir** : Walks through dir_path returning its contents.\n\n* **calculate_results** : Calculates model accuracy, precision, recall and f1 score of a binary classification model.","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\n# Create a function to import an image and resize it to be able to be used with our model\ndef load_and_prep_image(filename, img_shape=224, scale=True):\n  \"\"\"\n  Reads in an image from filename, turns it into a tensor and reshapes into\n  (224, 224, 3).\n\n  Parameters\n  ----------\n  filename (str): string filename of target image\n  img_shape (int): size to resize target image to, default 224\n  scale (bool): whether to scale pixel values to range(0, 1), default True\n  \"\"\"\n  # Read in the image\n  img = tf.io.read_file(filename)\n  # Decode it into a tensor\n  img = tf.image.decode_jpeg(img)\n  # Resize the image\n  img = tf.image.resize(img, [img_shape, img_shape])\n  if scale:\n    # Rescale the image (get all values between 0 and 1)\n    return img/255.\n  else:\n    return img\n\n# Note: The following confusion matrix code is a remix of Scikit-Learn's \n# plot_confusion_matrix function - https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html\nimport itertools\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\n\n# Our function needs a different name to sklearn's plot_confusion_matrix\ndef make_confusion_matrix(y_true, y_pred, classes=None, figsize=(10, 10), text_size=15, norm=False, savefig=False): \n  \"\"\"Makes a labelled confusion matrix comparing predictions and ground truth labels.\n\n  If classes is passed, confusion matrix will be labelled, if not, integer class values\n  will be used.\n\n  Args:\n    y_true: Array of truth labels (must be same shape as y_pred).\n    y_pred: Array of predicted labels (must be same shape as y_true).\n    classes: Array of class labels (e.g. string form). If `None`, integer labels are used.\n    figsize: Size of output figure (default=(10, 10)).\n    text_size: Size of output figure text (default=15).\n    norm: normalize values or not (default=False).\n    savefig: save confusion matrix to file (default=False).\n  \n  Returns:\n    A labelled confusion matrix plot comparing y_true and y_pred.\n\n  Example usage:\n    make_confusion_matrix(y_true=test_labels, # ground truth test labels\n                          y_pred=y_preds, # predicted labels\n                          classes=class_names, # array of class label names\n                          figsize=(15, 15),\n                          text_size=10)\n  \"\"\"  \n  # Create the confustion matrix\n  cm = confusion_matrix(y_true, y_pred)\n  cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] # normalize it\n  n_classes = cm.shape[0] # find the number of classes we're dealing with\n\n  # Plot the figure and make it pretty\n  fig, ax = plt.subplots(figsize=figsize)\n  cax = ax.matshow(cm, cmap=plt.cm.Blues) # colors will represent how 'correct' a class is, darker == better\n  fig.colorbar(cax)\n\n  # Are there a list of classes?\n  if classes:\n    labels = classes\n  else:\n    labels = np.arange(cm.shape[0])\n  \n  # Label the axes\n  ax.set(title=\"Confusion Matrix\",\n         xlabel=\"Predicted label\",\n         ylabel=\"True label\",\n         xticks=np.arange(n_classes), # create enough axis slots for each class\n         yticks=np.arange(n_classes), \n         xticklabels=labels, # axes will labeled with class names (if they exist) or ints\n         yticklabels=labels)\n  \n  # Make x-axis labels appear on bottom\n  ax.xaxis.set_label_position(\"bottom\")\n  ax.xaxis.tick_bottom()\n\n  # Set the threshold for different colors\n  threshold = (cm.max() + cm.min()) / 2.\n\n  # Plot the text on each cell\n  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    if norm:\n      plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n              horizontalalignment=\"center\",\n              color=\"white\" if cm[i, j] > threshold else \"black\",\n              size=text_size)\n    else:\n      plt.text(j, i, f\"{cm[i, j]}\",\n              horizontalalignment=\"center\",\n              color=\"white\" if cm[i, j] > threshold else \"black\",\n              size=text_size)\n\n  # Save the figure to the current working directory\n  if savefig:\n    fig.savefig(\"confusion_matrix.png\")\n  \n# Make a function to predict on images and plot them (works with multi-class)\ndef pred_and_plot(model, filename, class_names):\n  \"\"\"\n  Imports an image located at filename, makes a prediction on it with\n  a trained model and plots the image with the predicted class as the title.\n  \"\"\"\n  # Import the target image and preprocess it\n  img = load_and_prep_image(filename)\n\n  # Make a prediction\n  pred = model.predict(tf.expand_dims(img, axis=0))\n\n  # Get the predicted class\n  if len(pred[0]) > 1: # check for multi-class\n    pred_class = class_names[pred.argmax()] # if more than one output, take the max\n  else:\n    pred_class = class_names[int(tf.round(pred)[0][0])] # if only one output, round\n\n  # Plot the image and predicted class\n  plt.imshow(img)\n  plt.title(f\"Prediction: {pred_class}\")\n  plt.axis(False);\n  \nimport datetime\n\ndef create_tensorboard_callback(dir_name, experiment_name):\n  \"\"\"\n  Creates a TensorBoard callback instand to store log files.\n\n  Stores log files with the filepath:\n    \"dir_name/experiment_name/current_datetime/\"\n\n  Args:\n    dir_name: target directory to store TensorBoard log files\n    experiment_name: name of experiment directory (e.g. efficientnet_model_1)\n  \"\"\"\n  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n      log_dir=log_dir\n  )\n  print(f\"Saving TensorBoard log files to: {log_dir}\")\n  return tensorboard_callback\n\n# Plot the validation and training data separately\nimport matplotlib.pyplot as plt\n\ndef plot_loss_curves(history):\n  \"\"\"\n  Returns separate loss curves for training and validation metrics.\n\n  Args:\n    history: TensorFlow model History object (see: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/History)\n  \"\"\" \n  loss = history.history['loss']\n  val_loss = history.history['val_loss']\n\n  accuracy = history.history['accuracy']\n  val_accuracy = history.history['val_accuracy']\n\n  epochs = range(len(history.history['loss']))\n\n  # Plot loss\n  plt.plot(epochs, loss, label='training_loss')\n  plt.plot(epochs, val_loss, label='val_loss')\n  plt.title('Loss')\n  plt.xlabel('Epochs')\n  plt.legend()\n\n  # Plot accuracy\n  plt.figure()\n  plt.plot(epochs, accuracy, label='training_accuracy')\n  plt.plot(epochs, val_accuracy, label='val_accuracy')\n  plt.title('Accuracy')\n  plt.xlabel('Epochs')\n  plt.legend();\n\ndef compare_historys(original_history, new_history, initial_epochs=5):\n    \"\"\"\n    Compares two TensorFlow model History objects.\n    \n    Args:\n      original_history: History object from original model (before new_history)\n      new_history: History object from continued model training (after original_history)\n      initial_epochs: Number of epochs in original_history (new_history plot starts from here) \n    \"\"\"\n    \n    # Get original history measurements\n    acc = original_history.history[\"accuracy\"]\n    loss = original_history.history[\"loss\"]\n\n    val_acc = original_history.history[\"val_accuracy\"]\n    val_loss = original_history.history[\"val_loss\"]\n\n    # Combine original history with new history\n    total_acc = acc + new_history.history[\"accuracy\"]\n    total_loss = loss + new_history.history[\"loss\"]\n\n    total_val_acc = val_acc + new_history.history[\"val_accuracy\"]\n    total_val_loss = val_loss + new_history.history[\"val_loss\"]\n\n    # Make plots\n    plt.figure(figsize=(8, 8))\n    plt.subplot(2, 1, 1)\n    plt.plot(total_acc, label='Training Accuracy')\n    plt.plot(total_val_acc, label='Validation Accuracy')\n    plt.plot([initial_epochs-1, initial_epochs-1],\n              plt.ylim(), label='Start Fine Tuning') # reshift plot around epochs\n    plt.legend(loc='lower right')\n    plt.title('Training and Validation Accuracy')\n\n    plt.subplot(2, 1, 2)\n    plt.plot(total_loss, label='Training Loss')\n    plt.plot(total_val_loss, label='Validation Loss')\n    plt.plot([initial_epochs-1, initial_epochs-1],\n              plt.ylim(), label='Start Fine Tuning') # reshift plot around epochs\n    plt.legend(loc='upper right')\n    plt.title('Training and Validation Loss')\n    plt.xlabel('epoch')\n    plt.show()\n  \n# Create function to unzip a zipfile into current working directory \n# (since we're going to be downloading and unzipping a few files)\nimport zipfile\n\ndef unzip_data(filename):\n  \"\"\"\n  Unzips filename into the current working directory.\n\n  Args:\n    filename (str): a filepath to a target zip folder to be unzipped.\n  \"\"\"\n  zip_ref = zipfile.ZipFile(filename, \"r\")\n  zip_ref.extractall()\n  zip_ref.close()\n\n# Walk through an image classification directory and find out how many files (images)\n# are in each subdirectory.\nimport os\n\ndef walk_through_dir(dir_path):\n  \"\"\"\n  Walks through dir_path returning its contents.\n\n  Args:\n    dir_path (str): target directory\n  \n  Returns:\n    A print out of:\n      number of subdiretories in dir_path\n      number of images (files) in each subdirectory\n      name of each subdirectory\n  \"\"\"\n  for dirpath, dirnames, filenames in os.walk(dir_path):\n    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")\n    \n# Function to evaluate: accuracy, precision, recall, f1-score\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\n\ndef calculate_results(y_true, y_pred):\n  \"\"\"\n  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n\n  Args:\n      y_true: true labels in the form of a 1D array\n      y_pred: predicted labels in the form of a 1D array\n\n  Returns a dictionary of accuracy, precision, recall, f1-score.\n  \"\"\"\n  # Calculate model accuracy\n  model_accuracy = accuracy_score(y_true, y_pred) * 100\n  # Calculate model precision, recall and f1 score using \"weighted average\n  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n  model_results = {\"accuracy\": model_accuracy,\n                  \"precision\": model_precision,\n                  \"recall\": model_recall,\n                  \"f1\": model_f1}\n  return model_results","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-08-15T06:10:40.230019Z","iopub.execute_input":"2022-08-15T06:10:40.230617Z","iopub.status.idle":"2022-08-15T06:10:45.956763Z","shell.execute_reply.started":"2022-08-15T06:10:40.230523Z","shell.execute_reply":"2022-08-15T06:10:45.955722Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Loading the Dataset from TFDS","metadata":{}},{"cell_type":"code","source":"## Use TensorFlow Datasets to download dataset\nimport tensorflow_datasets as tfds","metadata":{"execution":{"iopub.status.busy":"2022-08-15T06:10:45.962557Z","iopub.execute_input":"2022-08-15T06:10:45.965656Z","iopub.status.idle":"2022-08-15T06:10:47.644989Z","shell.execute_reply.started":"2022-08-15T06:10:45.965618Z","shell.execute_reply":"2022-08-15T06:10:47.644021Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Listing some available datasets\ndatasets_list= tfds.list_builders()\ndatasets_list[:10]","metadata":{"execution":{"iopub.status.busy":"2022-08-15T06:10:47.648055Z","iopub.execute_input":"2022-08-15T06:10:47.648732Z","iopub.status.idle":"2022-08-15T06:10:48.796519Z","shell.execute_reply.started":"2022-08-15T06:10:47.648691Z","shell.execute_reply":"2022-08-15T06:10:48.79555Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Is our target dataset in list of tfds datasets?\nprint(\"food101\" in datasets_list)","metadata":{"execution":{"iopub.status.busy":"2022-08-15T06:10:48.799249Z","iopub.execute_input":"2022-08-15T06:10:48.799621Z","iopub.status.idle":"2022-08-15T06:10:48.80748Z","shell.execute_reply.started":"2022-08-15T06:10:48.799587Z","shell.execute_reply":"2022-08-15T06:10:48.806361Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load in data (It may take a bit time)\n(train_data, test_data), ds_info = tfds.load(name=\"food101\",\n                                             split = [\"train\", \"validation\"],\n                                             shuffle_files = True,\n                                             as_supervised = True, #returns as a tuple e.g (data,label)\n                                             with_info = True)","metadata":{"execution":{"iopub.status.busy":"2022-08-15T06:10:48.80881Z","iopub.execute_input":"2022-08-15T06:10:48.809255Z","iopub.status.idle":"2022-08-15T06:15:59.64435Z","shell.execute_reply.started":"2022-08-15T06:10:48.809219Z","shell.execute_reply":"2022-08-15T06:15:59.642448Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Analyse the Data","metadata":{}},{"cell_type":"markdown","source":"#### Features of dataset","metadata":{}},{"cell_type":"code","source":"ds_info.features","metadata":{"execution":{"iopub.status.busy":"2022-08-15T06:15:59.646176Z","iopub.execute_input":"2022-08-15T06:15:59.646843Z","iopub.status.idle":"2022-08-15T06:15:59.659199Z","shell.execute_reply.started":"2022-08-15T06:15:59.646789Z","shell.execute_reply":"2022-08-15T06:15:59.658089Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Get the class names","metadata":{}},{"cell_type":"code","source":"class_names = ds_info.features[\"label\"].names\nclass_names[:10]","metadata":{"execution":{"iopub.status.busy":"2022-08-15T06:15:59.663633Z","iopub.execute_input":"2022-08-15T06:15:59.665814Z","iopub.status.idle":"2022-08-15T06:16:00.562415Z","shell.execute_reply.started":"2022-08-15T06:15:59.66578Z","shell.execute_reply":"2022-08-15T06:16:00.561299Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Take one sample of train dataset","metadata":{}},{"cell_type":"code","source":"train_one_sample = train_data.take(1)\ntrain_one_sample","metadata":{"execution":{"iopub.status.busy":"2022-08-15T06:16:00.563994Z","iopub.execute_input":"2022-08-15T06:16:00.566271Z","iopub.status.idle":"2022-08-15T06:16:00.661297Z","shell.execute_reply.started":"2022-08-15T06:16:00.565885Z","shell.execute_reply":"2022-08-15T06:16:00.660298Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":" #### Output info about trainin sample","metadata":{}},{"cell_type":"code","source":" for image,label in train_one_sample:\n   print(f\"\"\"\n   Image shape: {image.shape}\n   Image datatype: {image.dtype}\n   Target class (tensor form): {label}\n   Class names : {class_names[label.numpy()]}\n   \"\"\")","metadata":{"execution":{"iopub.status.busy":"2022-08-15T06:16:00.662895Z","iopub.execute_input":"2022-08-15T06:16:00.664352Z","iopub.status.idle":"2022-08-15T06:16:02.220156Z","shell.execute_reply.started":"2022-08-15T06:16:00.664305Z","shell.execute_reply":"2022-08-15T06:16:02.219083Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### What does our image tensor look like?","metadata":{}},{"cell_type":"code","source":"image","metadata":{"execution":{"iopub.status.busy":"2022-08-15T06:16:02.224788Z","iopub.execute_input":"2022-08-15T06:16:02.225104Z","iopub.status.idle":"2022-08-15T06:16:02.240883Z","shell.execute_reply.started":"2022-08-15T06:16:02.225072Z","shell.execute_reply":"2022-08-15T06:16:02.23961Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### What are the min max values of our image?","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\ntf.reduce_min(image), tf.reduce_max(image)","metadata":{"execution":{"iopub.status.busy":"2022-08-15T06:16:02.242273Z","iopub.execute_input":"2022-08-15T06:16:02.242803Z","iopub.status.idle":"2022-08-15T06:16:03.201253Z","shell.execute_reply.started":"2022-08-15T06:16:02.242768Z","shell.execute_reply":"2022-08-15T06:16:03.200213Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Plot an image from the dataset :)","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(7,5))\nplt.title(class_names[label.numpy()])\nplt.imshow(image)\nplt.axis(False)","metadata":{"execution":{"iopub.status.busy":"2022-08-15T06:16:03.202879Z","iopub.execute_input":"2022-08-15T06:16:03.203551Z","iopub.status.idle":"2022-08-15T06:16:03.478569Z","shell.execute_reply.started":"2022-08-15T06:16:03.203512Z","shell.execute_reply":"2022-08-15T06:16:03.477636Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Preprocessing the Data","metadata":{}},{"cell_type":"markdown","source":"#### Create preprocessing functions for our data","metadata":{}},{"cell_type":"code","source":"def preprocess_image(image, label, image_shape=224):\n  \"\"\"\n  Converts image datatype from 'uint_8' -> 'float32' and reshapes image to\n  [img_shape, img_shape, colour_channels]\n  \"\"\"\n\n  image= tf.image.resize(image,[image_shape, image_shape]) # resize the target image\n  return tf.cast(image, tf.float32), label # returns tuple (float_32 image, label)","metadata":{"execution":{"iopub.status.busy":"2022-08-15T06:16:03.479736Z","iopub.execute_input":"2022-08-15T06:16:03.480046Z","iopub.status.idle":"2022-08-15T06:16:03.487362Z","shell.execute_reply.started":"2022-08-15T06:16:03.480017Z","shell.execute_reply":"2022-08-15T06:16:03.486346Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Preprocess a single image ","metadata":{}},{"cell_type":"code","source":"preprocessed_img = preprocess_image(image, label)[0]\nprint(f\"Feature of normal image -> Shape: {image.shape}, DataType: {image.dtype}\")\nprint(f\"Feature of preprocessed image -> Shape: {preprocessed_img.shape}, DataType: {preprocessed_img.dtype}\")","metadata":{"execution":{"iopub.status.busy":"2022-08-15T06:16:03.489548Z","iopub.execute_input":"2022-08-15T06:16:03.49062Z","iopub.status.idle":"2022-08-15T06:16:03.504557Z","shell.execute_reply.started":"2022-08-15T06:16:03.490583Z","shell.execute_reply":"2022-08-15T06:16:03.503474Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Batch and prepare datasets\ntrain_data = train_data.map(map_func= preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n\n# Shuffle train data and turn it into batches\ntrain_data = train_data.shuffle(buffer_size=1000).batch(batch_size=32).prefetch(buffer_size=tf.data.AUTOTUNE)\n\n# Map preprocessing function to test data\ntest_data = test_data.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE).batch(32).prefetch(tf.data.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2022-08-15T06:16:03.506032Z","iopub.execute_input":"2022-08-15T06:16:03.506453Z","iopub.status.idle":"2022-08-15T06:16:03.575672Z","shell.execute_reply.started":"2022-08-15T06:16:03.506413Z","shell.execute_reply":"2022-08-15T06:16:03.574809Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data, test_data","metadata":{"execution":{"iopub.status.busy":"2022-08-15T06:16:03.577096Z","iopub.execute_input":"2022-08-15T06:16:03.577438Z","iopub.status.idle":"2022-08-15T06:16:03.58394Z","shell.execute_reply.started":"2022-08-15T06:16:03.577404Z","shell.execute_reply":"2022-08-15T06:16:03.582877Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Creating callback function\n\nThis callback logs events for TensorBoard, including:\n\n* Metrics summary plots\n* Training graph visualization\n* Weight histograms\n* Sampled profiling","metadata":{}},{"cell_type":"markdown","source":"#### Create a model checkpoint callback","metadata":{}},{"cell_type":"code","source":"checkpoint_path = \"model_checkpoints/cp.ckpt\" \nmodel_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n                                                      monitor = \"val_acc\",\n                                                      save_best_only=True,\n                                                      save_weights_only=True,# saving weights easier than savign whole model\n                                                      verbose=0)","metadata":{"execution":{"iopub.status.busy":"2022-08-15T06:16:03.585609Z","iopub.execute_input":"2022-08-15T06:16:03.586441Z","iopub.status.idle":"2022-08-15T06:16:04.46678Z","shell.execute_reply.started":"2022-08-15T06:16:03.58637Z","shell.execute_reply":"2022-08-15T06:16:04.465847Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Mixed Precision\n\nMixed precision is the use of both 16-bit and 32-bit floating-point types in a model during training to make it run faster and use less memory. By keeping certain parts of the model in the 32-bit types for numeric stability, the model will have a lower step time and train equally as well in terms of the evaluation metrics such as accuracy. This guide describes how to use the Keras mixed precision API to speed up your models. Using this API can improve performance by more than 3 times on modern GPUs and 60% on TPUs.","metadata":{}},{"cell_type":"markdown","source":"#### Setup mixed precision training","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import mixed_precision\nmixed_precision.set_global_policy(\"mixed_float16\")","metadata":{"execution":{"iopub.status.busy":"2022-08-15T06:16:04.468136Z","iopub.execute_input":"2022-08-15T06:16:04.4692Z","iopub.status.idle":"2022-08-15T06:16:04.477246Z","shell.execute_reply.started":"2022-08-15T06:16:04.469158Z","shell.execute_reply":"2022-08-15T06:16:04.476236Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mixed_precision.global_policy()","metadata":{"execution":{"iopub.status.busy":"2022-08-15T06:16:04.478605Z","iopub.execute_input":"2022-08-15T06:16:04.479279Z","iopub.status.idle":"2022-08-15T06:16:04.496855Z","shell.execute_reply.started":"2022-08-15T06:16:04.479231Z","shell.execute_reply":"2022-08-15T06:16:04.495862Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Building the Model","metadata":{}},{"cell_type":"code","source":"# Feature Extraction Model\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers.experimental import preprocessing\n\n# Create base model\ninput_shape = (224,224,3)\nbase_model = tf.keras.applications.EfficientNetB0(include_top = False)\nbase_model.trainable= False\n\n# Create functional model\ninputs = layers.Input(shape=input_shape, name= \"input_layer\")\n# Note: Since EfficientNetBX models have rescaling no need to use preprocessing e.g. x= preprocessing.Rescaling(1/255.)\n\nx=base_model(inputs, training=False)\nx = layers.GlobalAveragePooling2D()(x)\nx = layers.Dense(len(class_names))(x)\noutputs = layers.Activation(\"softmax\", dtype=tf.float32, name =\"softmax_float32\")(x)\nmodel = tf.keras.Model(inputs,outputs)\n\n#Compile the model\nmodel.compile(loss = \"sparse_categorical_crossentropy\",\n              optimizer = tf.keras.optimizers.Adam(),\n              metrics=[\"accuracy\"])\n\n#Get a summary of model\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-08-15T06:16:04.498485Z","iopub.execute_input":"2022-08-15T06:16:04.49892Z","iopub.status.idle":"2022-08-15T06:16:09.14706Z","shell.execute_reply.started":"2022-08-15T06:16:04.498885Z","shell.execute_reply":"2022-08-15T06:16:09.14606Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for layer in model.layers:\n  print(layer.dtype)","metadata":{"execution":{"iopub.status.busy":"2022-08-15T06:16:09.148692Z","iopub.execute_input":"2022-08-15T06:16:09.14906Z","iopub.status.idle":"2022-08-15T06:16:09.158557Z","shell.execute_reply.started":"2022-08-15T06:16:09.149023Z","shell.execute_reply":"2022-08-15T06:16:09.153279Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Check the top ten layers of base model","metadata":{}},{"cell_type":"code","source":"from numpy import dtype\n\nfor layer in model.layers[1].layers[:10]:\n  print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)","metadata":{"execution":{"iopub.status.busy":"2022-08-15T06:16:09.160225Z","iopub.execute_input":"2022-08-15T06:16:09.160579Z","iopub.status.idle":"2022-08-15T06:16:11.311788Z","shell.execute_reply.started":"2022-08-15T06:16:09.160543Z","shell.execute_reply":"2022-08-15T06:16:11.310608Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Fit feature extraction model with callback","metadata":{}},{"cell_type":"code","source":"history_feature_extraction=model.fit(train_data,\n                                     epochs = 3,\n                                     steps_per_epoch=len(train_data),\n                                     validation_data= test_data,\n                                     validation_steps=(0.15*len(test_data)),\n                                     callbacks = [create_tensorboard_callback(dir_name = \"training_logs\",\n                                                                              experiment_name=\"efficientnetb0_101_classes_all_data_feature_extract\"),\n                                                  model_checkpoint])","metadata":{"execution":{"iopub.status.busy":"2022-08-15T06:16:11.313096Z","iopub.execute_input":"2022-08-15T06:16:11.313514Z","iopub.status.idle":"2022-08-15T06:25:40.431269Z","shell.execute_reply.started":"2022-08-15T06:16:11.313472Z","shell.execute_reply":"2022-08-15T06:25:40.430217Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results_feature_extraction_model = model.evaluate(test_data)\nresults_feature_extraction_model","metadata":{"execution":{"iopub.status.busy":"2022-08-15T06:25:40.433018Z","iopub.execute_input":"2022-08-15T06:25:40.433431Z","iopub.status.idle":"2022-08-15T06:26:28.253946Z","shell.execute_reply.started":"2022-08-15T06:25:40.433398Z","shell.execute_reply":"2022-08-15T06:26:28.253024Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Fine Tuning","metadata":{}},{"cell_type":"code","source":"base_model.trainable = True\n\nfor layer in base_model.layers[:-10]:\n  layer.trainable = False\n\n#Recompile the model\nmodel.compile(loss = \"sparse_categorical_crossentropy\",\n              optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001),\n              metrics=[\"accuracy\"])\n\nprint(len(model.trainable_variables))","metadata":{"execution":{"iopub.status.busy":"2022-08-15T06:26:28.255467Z","iopub.execute_input":"2022-08-15T06:26:28.255866Z","iopub.status.idle":"2022-08-15T06:26:28.285464Z","shell.execute_reply.started":"2022-08-15T06:26:28.255813Z","shell.execute_reply":"2022-08-15T06:26:28.28446Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Check which layers are trainable","metadata":{}},{"cell_type":"code","source":"for layer_number, layer in enumerate(model.layers[1].layers):\n  print(layer_number, layer.name, layer.trainable)","metadata":{"execution":{"iopub.status.busy":"2022-08-15T06:26:28.286791Z","iopub.execute_input":"2022-08-15T06:26:28.287173Z","iopub.status.idle":"2022-08-15T06:26:28.297427Z","shell.execute_reply.started":"2022-08-15T06:26:28.287109Z","shell.execute_reply":"2022-08-15T06:26:28.29627Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Early Stopping and Learning Rate Reduction Callbacks\n\n**Early Stopping Callback** stops training when a monitored metric has stopped improving.\n\n**Learning Rate Reduction Callback** reduces learning rate when a metric has stopped improving.","metadata":{}},{"cell_type":"code","source":"# Setup EarlyStopping callback to stop training if model's val_loss doesn't improve for 3 epochs\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", # watch the val loss metric\n                                                  patience=3)\n\n# Creating learning rate reduction callback\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",  \n                                                 factor=0.2, # multiply the learning rate by 0.2 (reduce by 5x)\n                                                 patience=2,\n                                                 verbose=1, # print out when learning rate goes down \n                                                 min_lr=1e-7)","metadata":{"execution":{"iopub.status.busy":"2022-08-15T06:26:28.299124Z","iopub.execute_input":"2022-08-15T06:26:28.299771Z","iopub.status.idle":"2022-08-15T06:26:28.30834Z","shell.execute_reply.started":"2022-08-15T06:26:28.299736Z","shell.execute_reply":"2022-08-15T06:26:28.307399Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Fit the Model","metadata":{}},{"cell_type":"markdown","source":"#### Fit feature extraction model with callback","metadata":{}},{"cell_type":"code","source":"history_fine_tuning=model.fit(train_data,\n                              epochs = 100,\n                              steps_per_epoch=len(train_data),\n                              validation_data= test_data,\n                              validation_steps=(0.15*len(test_data)),\n                              callbacks = [create_tensorboard_callback(dir_name = \"training_logs\",\n                                                                      experiment_name=\"efficientnetb0_101_classes_all_data_fine_tuning\"),\n                                           model_checkpoint,\n                                          early_stopping, # stop model after X epochs of no improvements\n                                           reduce_lr])","metadata":{"execution":{"iopub.status.busy":"2022-08-15T06:26:28.314323Z","iopub.execute_input":"2022-08-15T06:26:28.314961Z","iopub.status.idle":"2022-08-15T06:48:14.011536Z","shell.execute_reply.started":"2022-08-15T06:26:28.314934Z","shell.execute_reply":"2022-08-15T06:48:14.01057Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results_fine_tuned_model = model.evaluate(test_data)","metadata":{"execution":{"iopub.status.busy":"2022-08-15T06:48:14.013659Z","iopub.execute_input":"2022-08-15T06:48:14.014374Z","iopub.status.idle":"2022-08-15T06:49:00.04375Z","shell.execute_reply.started":"2022-08-15T06:48:14.014333Z","shell.execute_reply":"2022-08-15T06:49:00.042557Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Make predictions with model","metadata":{}},{"cell_type":"code","source":"pred_probs = model.predict(test_data, verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2022-08-15T06:49:00.045715Z","iopub.execute_input":"2022-08-15T06:49:00.046098Z","iopub.status.idle":"2022-08-15T06:49:45.317394Z","shell.execute_reply.started":"2022-08-15T06:49:00.046061Z","shell.execute_reply":"2022-08-15T06:49:45.316449Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### How many predictions are there?","metadata":{}},{"cell_type":"code","source":"len(pred_probs)","metadata":{"execution":{"iopub.status.busy":"2022-08-15T06:49:45.319337Z","iopub.execute_input":"2022-08-15T06:49:45.320032Z","iopub.status.idle":"2022-08-15T06:49:45.326894Z","shell.execute_reply.started":"2022-08-15T06:49:45.319993Z","shell.execute_reply":"2022-08-15T06:49:45.325835Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### For the first prediction, lets look at the probs","metadata":{}},{"cell_type":"code","source":"print(f\"Number of prediction probs for sample 0: {len(pred_probs[0])}\")\nprint(f\"What prediction probability sample looks like for sample 0: {pred_probs[0]}\")\nprint(f\"The class with the highest predicted probability for sample 0: {tf.argmax(pred_probs[0])}\")","metadata":{"execution":{"iopub.status.busy":"2022-08-15T06:57:44.568471Z","iopub.execute_input":"2022-08-15T06:57:44.568864Z","iopub.status.idle":"2022-08-15T06:57:44.578971Z","shell.execute_reply.started":"2022-08-15T06:57:44.568809Z","shell.execute_reply":"2022-08-15T06:57:44.577648Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"> <div class=\"alert alert-block alert-success\">\n<b>Success:</b> Don't Forget to upvote if you like the notebook\n</div>","metadata":{}}]}